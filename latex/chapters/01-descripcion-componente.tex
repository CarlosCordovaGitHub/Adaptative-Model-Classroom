\chapter{DESCRIPCIÓN DEL COMPONENTE}

Este proyecto se compone de cuatro componentes interrelacionados. El Componente B constituye el motor que traduce la evidencia de interacción del estudiante en decisiones pedagógicas accionables. Su función principal es calcular el nivel de habilidad del estudiante, identificar qué conocimientos domina con suficiente confianza y determinar qué actividad o ítem presentar a continuación, incluyendo la dificultad apropiada y el tipo de soporte necesario.\\

Los objetivos del componente son duales: por un lado, medir con precisión el desempeño del estudiante; por otro, favorecer el aprendizaje mediante trayectorias personalizadas, haciendo uso de la retroalimentación constante que mantiene con el Componente A, responsable de generar las actividades y las clases. Este enfoque se alinea con la lógica del aprendizaje adaptativo que predomina en la actualidad, basada en realizar ajustes del proceso de aprendizaje a partir de datos individuales en lugar de seguir rutas fijas predeterminadas \cite{ref1,ref2,ref3}.

\section{Objetivo general}

Desarrollar un motor adaptativo operativo que traduzca la evidencia de interacción del estudiante en decisiones pedagógicas fundamentadas, mediante la combinación de modelos psicométricos extensivamente validados IRT (Item Response Theory) y BKT/KT(Bayesian Knowledge Tracing / Knowledge Tracing) para medir con precisión el desempeño del estudiante y construir trayectorias de aprendizaje genuinamente personalizadas que se ajusten dinámicamente a partir de datos individuales.

\section{Objetivos específicos}

\begin{enumerate}
\item Desarrollar un sistema que recoja eventos de interacción y calcule dos señales complementarias: un nivel continuo de habilidad $\theta$ basado en IRT para ordenar ítems informativos y reducir el error estándar de medición, y una probabilidad de dominio por habilidad fundamentada en BKT/KT para guiar la práctica espaciada y el refuerzo cuando el objetivo sea consolidar conocimientos de forma sostenida.

\item Implementar una política de selección que escoja el ítem que maximiza la información en torno al $\theta$ estimado, reduciendo rápidamente el error estándar y permitiendo alcanzar precisión localizada donde más importa, incorporando reglas de detención, restricciones de contenido curricular y limitaciones de exposición siguiendo las buenas prácticas establecidas en IRT y CAT (Computerized Adaptive Testing).

\item Desarrollar mediante BKT/KT un sistema que mantenga una probabilidad de dominio por habilidad y la actualice tras cada interacción, modelando fenómenos como la adivinación y el desliz, de modo que la selección de la actividad subsiguiente se decida según el beneficio esperado: confirmar dominio incipiente, reducir incertidumbre o fomentar el aprendizaje en la zona de desarrollo más productiva.

\item Implementar el Componente B como un bucle MAPE-K (Monitor--Analyze--Plan--Execute over a Knowledge base)
que monitorice respuestas y patrones de desempeño, analice el perfil del estudiante, planifique la siguiente actividad especificando ítem, dificultad y tipo de apoyo, y ejecute enviando recomendaciones explícitas al Componente A, garantizando trazabilidad, explicabilidad y la posibilidad de integrar organización semántica del contenido mediante grafos o rutas de aprendizaje.

\item Establecer un contrato explícito de integración entre componentes que garantice trazabilidad.

\item Desarrollar salvaguardas que resguarden la validez y equidad mediante el reporte de precisión alcanzada, validación del ajuste del modelo, monitorización de exposición equilibrada de temas e ítems, reporte de ganancia pre--post, control de métricas predictivas como AUC(Area Under the Curve) o log-loss, y realización de pruebas DIF y análisis de brechas entre perfiles para detectar posibles sesgos.
\end{enumerate}


\section{Alcance del componente}

El alcance del Componente B comprende el desarrollo de un motor adaptativo operativo con las siguientes características funcionales y técnicas:

\begin{enumerate}[label=\roman*.]
  \item \textbf{Integración de modelos complementarios:} combinar IRT para diagnóstico o evaluación sumativa con BKT/KT para guiar la práctica continua, aprovechando las fortalezas de ambos enfoques para ofrecer una evaluación integral que mida y fomente el aprendizaje.
  \item \textbf{Orquestación de la selección de ítems:} orquestar la selección de ítems mediante reglas claras de parada, cobertura curricular y exposición equilibrada que permitan determinar cuándo la evaluación ha alcanzado suficiente precisión, garantizando que todos los temas relevantes sean cubiertos y evitando la sobreutilización de ítems específicos.
  \item \textbf{Panel de métricas para validación docente:} publicar un panel de métricas (precisión diagnóstica, eficiencia, progreso del estudiante, calidad predictiva y equidad) accesible para que los docentes validen el funcionamiento del sistema, facilitando la transparencia y permitiendo intervenciones informadas cuando resulte necesario.
  \item \textbf{Gobernanza de datos y privacidad:} documentar la gobernanza de datos y privacidad, especificando qué se registra, para qué propósito y cómo se protege la información, asegurando el cumplimiento de estándares éticos y regulatorios en el manejo de datos educativos sensibles.
\end{enumerate}

Todo ello integrado con el Componente A de manera que cada estudiante reciba un reto apropiado, en el momento oportuno, con las explicaciones y los apoyos adecuados a su nivel y necesidades específicas, logrando una experiencia de aprendizaje genuinamente personalizada y fundamentada en evidencia \cite{ref1,ref7,ref10}.

\section{Marco teórico}
\vspace{0.5cm}
\subsection{Aprendizaje adaptativo}

El aprendizaje adaptativo es una forma de enseñanza que se ajusta a cada estudiante en tiempo real. En vez de proponer la misma ruta para todos, el sistema observa evidencias (aciertos, errores, tiempo de respuesta, interacciones) y decide qué contenido, qué nivel de dificultad y qué apoyo conviene a continuación. Así, la progresión deja de ser lineal y se vuelve personalizada, manteniendo el foco en el dominio gradual de objetivos. Esta idea se formaliza y se sostiene en la literatura reciente sobre evaluación, personalización y uso responsable de IA (Inteligencia Artificial) en educación \cite{ref1,ref3}.\\

Conviene distinguir lo adaptativo de lo simplemente ''personalizado''. La personalización puede implicar variedad de actividades o estilos, pero no siempre supone que el sistema mida y ajuste continuamente con base en datos. Lo adaptativo, en cambio, depende de un ciclo continuo de diagnóstico-retroalimentación-reajuste, y se apoya en un buen diseño instruccional: objetivos claros, progresiones definidas y evidencias útiles para decidir los siguientes pasos \cite{ref3}.\\

En la práctica, el ciclo luce así:
\begin{enumerate}[label=\arabic*.]
  \item Un breve diagnóstico,
  \item Selección de recursos y tareas ajustadas al nivel detectado,
  \item Retroalimentación oportuna,
  \item Una nueva medición que confirma avances o sugiere refuerzos y
  \item Ajustes de la ruta.
\end{enumerate}

La clave no es aumentar la cantidad de ejercicios, sino ofrecer los adecuados en el momento preciso. Este principio didáctico se alinea con marcos como los de Reigeluth y los primeros principios de Merrill, que recomiendan activar saberes previos, demostrar, aplicar e integrar lo aprendido \cite{ref3}.\\

La IA generativa ha aportado un motor útil para redactar explicaciones, proponer ejemplos y crear ejercicios alineados con la ruta de cada estudiante. Sin embargo, la evidencia disponible también advierte que estas herramientas no reemplazan la pedagogía ni la evaluación rigurosa; su valor aumenta cuando operan bajo criterios claros de calidad, ética y supervisión docente \cite{ref1}.\\

Un ejemplo concreto es PathRAG (Path-based Retrieval-Augmented Generation), que organiza el conocimiento como un grafo (conceptos y relaciones) para trazar caminos pertinentes según el perfil del estudiante. Estudios recientes en contextos universitarios híbridos reportan mejoras en participación, logro de competencias y percepción de inclusión cuando se integran rutas personalizadas con apoyo de IA generativa; aun así, subrayan límites metodológicos y la necesidad de diseños más robustos \cite{ref2}.\\

\subsection{Teoría de Respuesta al Ítem (IRT)}
\vspace{0.5cm}

La Teoría de Respuesta al Ítem (TRI o IRT) es una forma moderna de entender las pruebas: en lugar de mirar solo el puntaje total, analiza cómo responde una persona a cada ítem y, a partir de ello, estima su nivel en el rasgo que se quiere medir $\theta$. Con esa estimación, es posible seleccionar mejores preguntas, ubicar la dificultad donde más hace falta y conocer cuán precisa es la medición en cada tramo del continuo. Frente a la Teoría Clásica de Tests, su aporte central es la 'invariancia': medir con la misma escala, aunque cambien los sujetos o los ítems (dentro de ciertos supuestos)  \cite{ref1,ref2}.\\

\textbf{Ideas clave}

\begin{itemize}
  \item \textbf{Curva característica del ítem (CCI):} es un gráfico que muestra, para cada nivel de  $\theta$, la probabilidad de elegir la opción ''clave'' del ítem (por ejemplo, responder correctamente o indicar mayor rasgo). Su forma creciente refleja que, a mayor nivel del rasgo, mayor probabilidad de dar la respuesta asociada al rasgo \cite{ref1,ref2}.
  \item \textbf{Parámetros $a$, $b$ y $c$:} $a$ indica cuánto discrimina el ítem (qué tan bien separa a personas con niveles cercanos de  $\theta$), $b$ ubica la dificultad del ítem (el punto de la escala donde el ítem ''decide''), y  $c$ modela el azar o pseudo-adivinación en ítems de opción correcta/incorrecta. No todos los modelos usan los tres: Rasch 1PL (One-Parameter Logistic Model) usa solo b, 2PL (Two-Parameter Logistic Model) usa a y b, y 3PL (Three-Parameter Logistic Model) usa a, b, c \cite{ref1,ref2}.
  \item \textbf{Información del ítem/test:} indica dónde el ítem o el conjunto de ítems mide con mayor precisión. En IRT la precisión no es ''plana'': puede ser excelente en un rango de $\theta$ y más baja en otros. Esto permite construir bancos de ítems que ''cubran'' la escala con precisión donde más importa \cite{ref2}.
\end{itemize}

\textbf{Supuestos relevantes}

\begin{itemize}
  \item \textbf{Unidimensionalidad:} los ítems de una escala deben reflejar esencialmente un solo rasgo dominante; si influyen varios rasgos a la vez, conviene usar modelos multidimensionales o depurar la escala \cite{ref2}.
  \item \textbf{Independencia local:} si ya sabemos el nivel de $\theta$, las respuestas a ítems distintos no deben depender entre sí. Cuando hay ''pistas'' entre ítems o se agrupan demasiado, este supuesto se rompe y la medición pierde calidad \cite{ref1,ref2}.
\end{itemize}

\textbf{Modelos más usados (visión práctica)}

\begin{itemize}
  \item \textbf{Ítems dicotómicos (correcto/incorrecto):} 1PL (Rasch), 2PL y 3PL. Rasch asume igual discriminación y sin azar; 2PL permite que la discriminación varíe; 3PL incluye el parámetro de pseudo-adivinación. Elegir el modelo depende del contexto y los datos \cite{ref1,ref2}.
  \item \textbf{Ítems politómicos (escalas Likert):} modelos como Respuesta Graduada (Samejima) o Crédito Parcial. En el Modelo de Respuesta Graduada, cada salto entre categorías tiene un ''umbral'' de dificultad, y un único parámetro $a$ de discriminación para el ítem. Esto es muy útil para cuestionarios con varias opciones de respuesta \cite{ref5}.
\end{itemize}
\vspace{0.5cm}
\textbf{Bancos de ítems y pruebas adaptativas (CAT)}
\vspace{0.5cm}

Al estimar $\theta$ en tiempo real y conocer la información de cada ítem, es posible elegir la siguiente pregunta que aporte máxima precisión justo alrededor del nivel estimado del estudiante. Así nacen los tests adaptativos: cada persona responde un conjunto distinto de preguntas, pero todos son evaluados en la misma escala. En este proyecto, esto es clave para que el Componente B seleccione o recomiende ítems con mayor ''ganancia informativa'' \cite{ref4,ref5}.\\

\textbf{Integración con los Componentes A y B}
\vspace{0.5cm}

\begin{enumerate}[label=\arabic*.]
  \item \textbf{(B)} a partir de las respuestas del estudiante, se estima $\theta$ con un modelo IRT apropiado (2PL/3PL para ítems dicotómicos; Respuesta Graduada para Likert).
  \item \textbf{(B)} se consulta el banco de ítems para identificar cuáles ofrecen más información alrededor del $\theta$ actual (o del umbral de dominio). 
  \item \textbf{(B$\rightarrow$A)} se envía al Componente A la dificultad objetivo y, si aplica, los ítems recomendados o las pautas de complejidad. 
  \item \textbf{(A)} el Componente A genera la siguiente actividad con esa dificultad y pistas adecuadas. 
  \item \textbf{(B)} tras la actividad, se actualiza $\theta$ y se repite el ciclo. Este bucle mantiene rutas personalizadas y medibles  \cite{ref5,ref6}.
\end{enumerate}

\subsection{Sistemas de Tutoría Inteligente (ITS)}
\vspace{0.5cm}

Un Sistema de Tutoría Inteligente (ITS por sus siglas en inglés Intelligent Tutoring Systems) es un software que intenta ''parecerse'' a una tutoría humana: observa cómo aprende el estudiante, le ofrece explicaciones y actividades a la medida, y retroalimenta en los momentos clave. La idea no es reemplazar al docente, sino multiplicar su apoyo para que cada persona avance a su propio ritmo y con la ayuda justa. Las revisiones recientes muestran que, bien implementados, los ITS mejoran el rendimiento y la participación, personalizan contenidos y apoyan la autorregulación del aprendizaje \cite{ref7}.\\

\textbf{Componentes típicos}

\begin{itemize}
  \item \textbf{Modelo del estudiante:} mantiene un ''perfil vivo'' con aciertos, errores, tiempos y progreso. 
  \item \textbf{Modelo del tutor:} decide qué explicar, qué actividad proponer y qué pista dar. 
  \item \textbf{Modelo de dominio:} representa el conocimiento de la materia (conceptos, habilidades, reglas).
  \item \textbf{Interfaz:} es la cara del sistema (pantallas, ejercicios, feedback). 
\end{itemize}

Con estos componentes, el ITS puede ajustar dificultad, secuencias y apoyos en tiempo real \cite{ref8}.\\

\textbf{Integración con los Componentes A y B}

\begin{enumerate}[label=\arabic*.]
  \item \textbf{(B)} Observa respuestas, estima el nivel del estudiante en los temas clave y detecta dificultades.
  \item \textbf{(B$\rightarrow$A)} Envía al Componente A la dificultad recomendada, objetivos prioritarios y el tipo de intervención.
  \item \textbf{(A)} El Componente A genera la actividad/clase con esa dificultad y apoyo. 
  \item \textbf{(B)} Tras la actividad, el ITS vuelve a medir y ajusta la ruta. Este bucle mantiene trayectorias personalizadas y medibles a lo largo del curso \cite{ref7,ref8}.
\end{enumerate}

\subsection{Algoritmos de selección adaptativa}
\vspace{0.5cm}

Seleccionar ''lo siguiente'' no es al azar: es decidir, con evidencia, cuál actividad o ítem conviene presentar para medir mejor o para ayudar a aprender mejor. En este proyecto, esa decisión vive en el Componente B (evaluación) y retroalimenta al Componente A (generación de clases). A grandes rasgos, hay dos familias bien establecidas: selección guiada por IRT (cuando buscamos medir con precisión) y selección guiada por BKT/KT (cuando buscamos acompañar la adquisición de habilidades en el tiempo).\\

\begin {enumerate}[label=\arabic*.]
\item \textbf{Selección guiada por IRT (medición precisa)}
\vspace{0.5cm}

La Teoría de Respuesta al Ítem (IRT) modela la probabilidad de respuesta correcta según el nivel del rasgo latente $\theta$ y los parámetros del ítem. De forma general, esta relación puede expresarse mediante una función logística, como en el modelo 2PL:

\[
P(X_{ij}=1 \mid \theta_j) = \frac{1}{1 + e^{-a_i(\theta_j - b_i)}}
\]

donde $a_i$ representa la discriminación del ítem y $b_i$ su dificultad. Con esa base, la selección adaptativa típica elige el siguiente ítem con más información alrededor del $\theta$ estimado del estudiante. Esto reduce el error estándar de medición con menos preguntas y mantiene la dificultad ''justo donde más informa''. La información de un ítem puede expresarse como:

\[
I_i(\theta) = a_i^2 \, P_i(\theta)\bigl(1 - P_i(\theta)\bigr)
\]

y el error estándar asociado a la estimación de $\theta$ se define como:

\[
SE(\theta) = \frac{1}{\sqrt{I(\theta)}}
\]

En la práctica, se inicia con un $\theta$ neutro o con un breve arranque \textit{warm-up}; y tras cada respuesta se reestima $\theta$ y se elige el ítem que maximiza la información, lo que puede formalizarse como:

\[
i^* = \arg\max_{i \in \mathcal{B}} I_i(\hat{\theta})
\]

donde $\mathcal{B}$ representa el conjunto de ítems disponibles tras aplicar restricciones. Para mantener validez y equidad, se aplican restricciones de contenido (temas/objetivos), control de exposición (evitar sobre--uso de ciertos ítems) y límites de longitud o precisión objetivo. En escalas politómicas (tipo Likert), la lógica es análoga: cada categoría aporta información en zonas distintas de la escala, y la selección prioriza donde la precisión es más útil \cite{ref4,ref5}.\\

El Componente A$\leftrightarrow$B actúa cuando el objetivo es certificar dominio o ubicar con exactitud el nivel, IRT permite pedir menos y medir mejor. El Componente B devuelve a A el rango de dificultad recomendada (y la cobertura temática pendiente), de modo que A genere actividades acordes a ese nivel y no ''sobre--o--subestime'' la exigencia \cite{ref4,ref5}.\\

\item \textbf{Selección guiada por BKT/KT (apoyo al aprendizaje)}
\vspace{0.5cm}

Seguimiento Bayesiano del Conocimiento (BKT) sigue, para cada habilidad, la probabilidad de dominio del estudiante a lo largo del tiempo: considera un estado ''domina / no domina'' y cuatro parámetros intuitivos (conocimiento inicial, probabilidad de aprender tras una práctica, adivinación y desliz). Tras una respuesta correcta, la probabilidad de dominio puede actualizarse como:

\[
P(L_n \mid Correcto) =
\frac{P(L_n)(1 - S)}{P(L_n)(1 - S) + (1 - P(L_n))G}
\]
\vspace{0.5cm}
y posteriormente incorporar la posibilidad de aprendizaje mediante:

\[
P(L_{n+1}) = P(L_n \mid obs) + (1 - P(L_n \mid obs))T
\]

donde $T$ representa la probabilidad de transición al dominio, $S$ el desliz y $G$ la adivinación. Con ese perfil, el sistema decide el siguiente ejercicio según el mayor beneficio esperado: reducir la incertidumbre, confirmar dominio o provocar aprendizaje en la zona adecuada. Esta decisión puede formularse de manera general como:

\[
a^* = \text{arg max}_{a}\; E(P(L_{n+1}) - P(L_n))
\]

En contextos reales se combinan además prerequisitos, espaciado para combatir el olvido y señales de compromiso (tiempos, rachas). La evidencia reciente muestra que BKT es eficaz para personalizar secuencias y mejorar resultados cuando la meta es progresar en habilidades específicas y no sólo ''medir una vez con precisión'' \cite{ref9,ref11}.\\

El aporte dentro del flujo entre los Componentes A$\leftrightarrow$B, BKT entrega al Componente A no sólo una dificultad recomendada, sino también la habilidad prioritaria, el tipo de apoyo (pista, ejemplo guiado, práctica adicional) y el momento oportuno para espaciado o refuerzo. Tras la actividad de A, B actualiza las probabilidades de dominio y repite el ciclo \cite{ref10,ref11}.\\

\item \textbf{Estrategia híbrida}
\vspace{0.5cm}

En etapas tempranas o con bancos pequeños, BKT tiende a funcionar mejor porque necesita menos calibración de ítems y entrega señales útiles para enseñar. Cuando el banco crece y se busca una estimación fina del nivel, IRT gana relevancia: permite fijar una precisión objetivo y optimizar la ruta de ítems. Una política práctica es: usar BKT para guiar la práctica diaria (progreso por habilidades) y activar selección IRT en cortes de evaluación (diagnósticos o certificaciones). Esta lógica puede expresarse como una política de selección dependiente del objetivo:

\[
\pi(s) =
\begin{cases}
\text{BKT}(s), & \text{si el objetivo es aprendizaje} \\
\text{IRT}(s), & \text{si el objetivo es medición}
\end{cases}
\]\\

En la arquitectura del proyecto, esto se implementa como un bucle MAPE-K: Monitorizar (respuestas), Analizar (IRT/BKT), Planificar (siguiente ítem o actividad) y Ejecutar (enviar a A), con conocimiento compartido del perfil del estudiante y del banco de ítems \cite{ref10}.\\

\end{enumerate}

\subsection{Métricas de desempeño en sistemas adaptativos}
\vspace{0.5cm}

Las métricas no son un listado de números: son la forma en que demostramos que el sistema realmente ayuda a aprender y que lo hace de manera eficiente y justa. En un entorno adaptativo, medir implica dos planos que se retroalimentan: la calidad de la medición (\textquestiondown qué tan bien estimamos el nivel del estudiante?) y la calidad de la enseñanza (\textquestiondown qué tan bien estimamos el nivel del estudiante?). A continuación se presentan métricas nucleares, escritas en lenguaje claro, conectando la literatura de pruebas adaptativas y trazado del conocimiento \cite{ref4, ref12}.\\

\begin{enumerate}[label=\arabic*.]
\item \textbf{Métricas de precisión en la estimación del nivel del estudiante}

Para evaluar la calidad de la medición en sistemas adaptativos basados en IRT, es fundamental cuantificar qué tan bien el modelo estima el nivel de habilidad real del estudiante. Tres métricas clave permiten esta valoración:

\begin{itemize}
    \item \textbf{Root Mean Square Error (RMSE):}  
    cuantifica la magnitud promedio del error entre el nivel estimado $\hat{\theta}$ y el nivel real $\theta$ del estudiante. Un RMSE bajo indica que las estimaciones del sistema son precisas y se aproximan al verdadero nivel de habilidad. Esta métrica es especialmente útil para comparar diferentes algoritmos de estimación o configuraciones del sistema adaptativo \cite{ref6,ref7}.

    \item \textbf{Expected A Posteriori (EAP):}  
    es un método de estimación bayesiano que calcula el valor esperado de $\theta$ dada la distribución posterior. A diferencia del \textit{Maximum Likelihood Estimation} (MLE), EAP incorpora información previa y es más robusto con respuestas limitadas, evitando estimaciones extremas. En contextos adaptativos, EAP permite actualizar continuamente la estimación del nivel del estudiante con cada nueva respuesta, manteniendo estabilidad incluso en las etapas iniciales de la evaluación \cite{ref6,ref7,ref12}.

    \item \textbf{Ranked Probability Score (RPS):}  
    evalúa la precisión de las predicciones probabilísticas en ítems politómicos ordenados (como escalas Likert). RPS penaliza las predicciones erróneas proporcionalmente a la distancia entre la categoría predicha y la categoría observada, siendo particularmente útil cuando el Componente B trabaja con respuestas graduadas que reflejan diferentes niveles de dominio parcial \cite{ref12}.
\end{itemize}

\textbf{Calibración predictiva:}

\begin{itemize}
    \item \textbf{Brier Score:} error cuadrático medio entre probabilidades predichas y resultados observados, calculado como:
    \[
    \text{Brier} = \frac{1}{N} \sum (p_i - o_i)^2
    \]
    donde $p_i$ es la probabilidad predicha de respuesta correcta y $o_i$ el resultado observado (1 si correcta, 0 si incorrecta). Valores cercanos a 0.0 indican predicciones bien calibradas; el valor de referencia 0.25 corresponde a predicciones aleatorias \cite{ref11,ref12}.

\end{itemize}

\textbf{Eficiencia evaluativa:}

\begin{itemize}
    \item \textbf{Número de ítems hasta convergencia:} cantidad de ítems requeridos para alcanzar SE($\hat{\theta}$) $\leq 0.4$, permitiendo evaluar el costo evaluativo del algoritmo adaptativo \cite{ref7}.

    \item \textbf{Latencia de respuesta del sistema:} tiempo entre recepción de respuesta y generación del siguiente ítem. Latencias superiores a 500 ms pueden degradar perceptiblemente la experiencia del usuario \cite{ref5}.
\end{itemize}

Estas métricas permiten al Componente B no solo estimar el nivel del estudiante, sino también evaluar la confiabilidad de sus propias estimaciones, ajustando dinámicamente la selección de ítems para maximizar la precisión con el mínimo número de preguntas \cite{ref6,ref7,ref12}.

\item \textbf{Componentes típicos}
\vspace{0.5cm}

\begin{itemize}
  \item \textbf{Modelo del estudiante:} mantiene un ``perfil vivo'' con aciertos, errores, tiempos y progreso. 
  \item \textbf{Modelo del tutor:} decide qué explicar, qué actividad proponer y qué pista dar. 
  \item \textbf{Modelo de dominio:} representa el conocimiento de la materia (conceptos, habilidades, reglas).
  \item \textbf{Interfaz:} es la cara del sistema (pantallas, ejercicios, feedback). 
\end{itemize}

Con estos componentes, el ITS puede ajustar dificultad, secuencias y apoyos en tiempo real \cite{ref8}.\\

\end{enumerate}


\textbf{Integración con los Componentes A y B}

\begin{enumerate}[label=\arabic*.]
  \item \textbf{(B)} Observa respuestas, estima el nivel del estudiante en los temas clave y detecta dificultades.
  \item \textbf{(B$\rightarrow$A)} Envía al Componente A la dificultad recomendada, objetivos prioritarios y el tipo de intervención.
  \item \textbf{(A)} El Componente A genera la actividad/clase con esa dificultad y apoyo. 
  \item \textbf{(B)} Tras la actividad, el ITS vuelve a medir y ajusta la ruta. Este bucle mantiene trayectorias personalizadas y medibles a lo largo del curso \cite{ref7,ref8}.
\end{enumerate}

\textbf{Reporte para la integración A$\leftrightarrow$B}
\vspace{0.5cm}

Para cerrar el ciclo A$\leftrightarrow$B, el Componente B debe devolver un panel compacto: (i) precisión alcanzada ($SE(\hat{\theta})$, o intervalo de confianza de puntaje/total), (ii) eficiencia (ítems/tiempo vs. objetivo), (iii) progreso por habilidad (probabilidad de dominio y ganancia), (iv) calidad de predicción (AUC/log‑loss) y (v) equidad (DIF y exposición balanceada). Con ese resumen, el Componente A puede ajustar dificultad, apoyo y espaciado con criterio.\\

\subsection{Tabla de herramientas y tecnologías}
\vspace{0.5cm}

A continuación, la Tabla \ref{tabla:herramientas_componente_b} presenta las herramientas y tecnologías empleadas en el desarrollo del Componente B (Motor Adaptativo), detallando su uso específico dentro del sistema.

\begin{table}[H]
\centering
\captionsetup{justification=centering}
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{10cm}|}
\hline
\textbf{Herramienta / Tecnología} & \textbf{Uso dentro del Componente B} \\ \hline

\centering
\textbf{Python 3.x}\\
\vspace{2pt}
\includegraphics[width=0.9cm]{figures/python-logo.png}
&
Lenguaje de programación principal para la implementación del motor adaptativo, la lógica de negocio y los cálculos psicométricos (IRT y BKT). \\ \hline


\centering
\textbf{FastAPI}\\
\vspace{2pt}
\includegraphics[width=2cm]{figures/fastapi_logo.png}
&
Framework para la exposición del motor adaptativo como API REST, encargado de la gestión de eventos, recomendaciones y métricas del sistema. \\ \hline

\centering
\textbf{Pydantic}\\
\vspace{2pt}
\includegraphics[width=2.5cm]{figures/pydantic-ai-logo.png}
&
Librería para el modelado y validación tipada de datos intercambiados entre los endpoints del servicio. \\ \hline

\centering
\textbf{OpenAPI / Swagger}\\
\vspace{2pt}
\includegraphics[width=1cm]{figures/swagger-logo.png}
&
Interfaz de documentación automática para la exploración y prueba de los endpoints del Componente B. \\ \hline

\centering
\textbf{jsonschema}\\
\vspace{2pt}
\includegraphics[width=3cm]{figures/jsonschema.png}
&
Herramienta para la validación formal de los contratos de integración A→B y B→A. \\ \hline

\centering
\textbf{Estructuras JSON}\\
\vspace{2pt}
\includegraphics[width=1cm]{figures/JSON_logo.png}
&
Formato de datos utilizado para la persistencia del estado del estudiante y la configuración del motor adaptativo. \\ \hline

\centering
\textbf{Logging estructurado}\\
\vspace{2pt}
\includegraphics[width=0.9cm]{figures/logging_logo.png}
&
Mecanismo de registro en formato JSON para auditoría y trazabilidad de decisiones adaptativas. \\ \hline

\centering
\textbf{Uvicorn}\\
\vspace{2pt}
\includegraphics[width=1cm]{figures/uvicorn_logo.png}
&
Servidor ASGI empleado para la ejecución concurrente del servicio FastAPI en entornos de desarrollo y prueba. \\ \hline

\centering
\textbf{dateutil}\\
\vspace{2pt}
\includegraphics[width=3cm]{figures/dateutil_logo.png}
&
Librería para el manejo de fechas y tiempos en el cálculo de decaimiento temporal del modelo BKT. \\ \hline

\centering
\textbf{Locust}\\
\vspace{2pt}
\includegraphics[width=3cm]{figures/locust_logo.png}
&
Herramienta para la evaluación del rendimiento y la carga concurrente del sistema. \\ \hline

\end{tabular}
\caption{Herramientas y tecnologías empleadas en el desarrollo del Componente B (Motor Adaptativo)}
\label{tabla:herramientas_componente_b}
\end{table}

